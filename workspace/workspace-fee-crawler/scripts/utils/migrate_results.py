#!/usr/bin/env python3
"""
ê¸°ì¡´ src/data_processing/results í´ë”ì˜ íŒŒì¼ë“¤ì„
ìƒˆë¡œìš´ data/outputs êµ¬ì¡°ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜

672MB, 855ê°œ íŒŒì¼ì„ ë‚ ì§œë³„ë¡œ ì •ë¦¬í•˜ì—¬ ì´ë™
"""

import os
import shutil
from pathlib import Path
from datetime import datetime
import re
from collections import defaultdict

def parse_filename_date(filename):
    """íŒŒì¼ëª…ì—ì„œ ë‚ ì§œ ì¶”ì¶œ (YYYYMMDD_HHMMSS)"""
    match = re.search(r'(\d{8})_(\d{6})', filename)
    if match:
        date_str = match.group(1)
        return date_str
    return None

def migrate_results():
    """results í´ë” ë§ˆì´ê·¸ë ˆì´ì…˜"""

    # ê²½ë¡œ ì„¤ì •
    old_results_dir = Path("src/data_processing/results")
    new_merged_archive = Path("data/outputs/merged/archive")
    new_summary_archive = Path("data/outputs/summary/archive")

    if not old_results_dir.exists():
        print("âŒ src/data_processing/results í´ë”ê°€ ì—†ìŠµë‹ˆë‹¤")
        return

    # í†µê³„
    stats = {
        'total': 0,
        'migrated': 0,
        'skipped': 0,
        'by_date': defaultdict(int),
        'by_type': defaultdict(int)
    }

    print("="*60)
    print("ðŸ“¦ Results í´ë” ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹œìž‘")
    print("="*60)
    print(f"Source: {old_results_dir}")
    print(f"Target: {new_merged_archive}")
    print("")

    # ëª¨ë“  íŒŒì¼ ìŠ¤ìº”
    all_files = list(old_results_dir.glob("*.xlsx")) + list(old_results_dir.glob("*.csv"))
    stats['total'] = len(all_files)

    print(f"ì´ {stats['total']}ê°œ íŒŒì¼ ë°œê²¬")
    print("")

    # íŒŒì¼ë³„ë¡œ ì²˜ë¦¬
    for file_path in all_files:
        filename = file_path.name

        # ë‚ ì§œ ì¶”ì¶œ
        date_str = parse_filename_date(filename)

        if date_str is None:
            print(f"âš ï¸  ë‚ ì§œ íŒŒì‹± ì‹¤íŒ¨ (ê±´ë„ˆëœ€): {filename}")
            stats['skipped'] += 1
            continue

        # íŒŒì¼ ìœ í˜• íŒë³„
        if 'summary' in filename.lower():
            # Summary íŒŒì¼
            target_dir = new_summary_archive / date_str
            file_type = 'summary'
        elif any(carrier in filename.lower() for carrier in ['kt_', 'sk_', 'lg_']):
            # Merged íŒŒì¼
            target_dir = new_merged_archive / date_str
            file_type = 'merged'
        else:
            print(f"âš ï¸  ì•Œ ìˆ˜ ì—†ëŠ” íŒŒì¼ ìœ í˜• (ê±´ë„ˆëœ€): {filename}")
            stats['skipped'] += 1
            continue

        # ë””ë ‰í† ë¦¬ ìƒì„±
        target_dir.mkdir(parents=True, exist_ok=True)

        # íŒŒì¼ ì´ë™
        target_path = target_dir / filename

        # ì¤‘ë³µ íŒŒì¼ í™•ì¸
        if target_path.exists():
            print(f"   â­ï¸  ì´ë¯¸ ì¡´ìž¬ (ê±´ë„ˆëœ€): {filename}")
            stats['skipped'] += 1
            continue

        try:
            shutil.copy2(file_path, target_path)
            stats['migrated'] += 1
            stats['by_date'][date_str] += 1
            stats['by_type'][file_type] += 1

            # ì§„í–‰ ìƒí™© í‘œì‹œ (100ê°œë§ˆë‹¤)
            if stats['migrated'] % 100 == 0:
                print(f"   ì§„í–‰ ì¤‘... {stats['migrated']}/{stats['total']} íŒŒì¼ ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")

        except Exception as e:
            print(f"âŒ ë³µì‚¬ ì‹¤íŒ¨: {filename} - {e}")
            stats['skipped'] += 1

    # ê²°ê³¼ ì¶œë ¥
    print("")
    print("="*60)
    print("ðŸ“Š ë§ˆì´ê·¸ë ˆì´ì…˜ ê²°ê³¼")
    print("="*60)
    print(f"âœ… ì„±ê³µ: {stats['migrated']}ê°œ íŒŒì¼")
    print(f"â­ï¸  ê±´ë„ˆëœ€: {stats['skipped']}ê°œ íŒŒì¼")
    print(f"ðŸ“ ì´ íŒŒì¼: {stats['total']}ê°œ")
    print("")

    print("íŒŒì¼ ìœ í˜•ë³„:")
    for file_type, count in stats['by_type'].items():
        print(f"  - {file_type}: {count}ê°œ")
    print("")

    print("ë‚ ì§œë³„ íŒŒì¼ ìˆ˜ (ìƒìœ„ 10ê°œ):")
    sorted_dates = sorted(stats['by_date'].items(), key=lambda x: x[1], reverse=True)
    for date_str, count in sorted_dates[:10]:
        formatted_date = f"{date_str[:4]}-{date_str[4:6]}-{date_str[6:8]}"
        print(f"  - {formatted_date}: {count}ê°œ")

    if len(sorted_dates) > 10:
        print(f"  ... ì™¸ {len(sorted_dates) - 10}ê°œ ë‚ ì§œ")

    print("")
    print("="*60)
    print("ðŸ’¡ ì›ë³¸ íŒŒì¼ì€ ê·¸ëŒ€ë¡œ ìœ ì§€ë©ë‹ˆë‹¤")
    print("   ì‚­ì œí•˜ë ¤ë©´: rm -rf src/data_processing/results/*.xlsx")
    print("="*60)

def clean_old_results():
    """ë§ˆì´ê·¸ë ˆì´ì…˜ í›„ ì›ë³¸ íŒŒì¼ ì •ë¦¬ (ì„ íƒì‚¬í•­)"""
    old_results_dir = Path("src/data_processing/results")

    print("")
    print("âš ï¸  ì›ë³¸ íŒŒì¼ ì •ë¦¬ë¥¼ ì‹œìž‘í•©ë‹ˆë‹¤")
    print("   ì´ ìž‘ì—…ì€ ë˜ëŒë¦´ ìˆ˜ ì—†ìŠµë‹ˆë‹¤!")

    response = input("\nê³„ì†í•˜ì‹œê² ìŠµë‹ˆê¹Œ? (yes/no): ")

    if response.lower() == 'yes':
        # Excel íŒŒì¼ë§Œ ì‚­ì œ (í´ë”ëŠ” ìœ ì§€)
        xlsx_files = list(old_results_dir.glob("*.xlsx"))
        csv_files = list(old_results_dir.glob("*.csv"))

        total = len(xlsx_files) + len(csv_files)

        for file_path in xlsx_files + csv_files:
            file_path.unlink()

        print(f"âœ… {total}ê°œ íŒŒì¼ ì‚­ì œ ì™„ë£Œ")
        print(f"ðŸ“ {old_results_dir} í´ë”ëŠ” ìœ ì§€ë¨")
    else:
        print("âŒ ì·¨ì†Œë¨")

if __name__ == "__main__":
    import sys

    # ë§ˆì´ê·¸ë ˆì´ì…˜ ì‹¤í–‰
    migrate_results()

    # ì •ë¦¬ ì˜µì…˜
    if len(sys.argv) > 1 and sys.argv[1] == "--clean":
        clean_old_results()
