#!/usr/bin/env python3
"""
ë£¨íŠ¸ ë ˆë²¨ ê¸°ëŠ¥ë³„ í´ë” êµ¬ì¡°ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸

ê¸°ì¡´: data/crawler/, data/ocr/, data/merge/, data/summary/
ìƒˆë¡œìš´: crawler/, ocr/, merge/, summary/ (ë£¨íŠ¸ ë ˆë²¨)
"""

import shutil
from pathlib import Path
from datetime import datetime
from zoneinfo import ZoneInfo

def migrate_to_root():
    """data/* í•˜ìœ„ì˜ ê¸°ëŠ¥ í´ë”ë“¤ì„ ë£¨íŠ¸ ë ˆë²¨ë¡œ ì´ë™"""
    base_dir = Path(__file__).parent.parent.parent

    print("=" * 60)
    print("ë£¨íŠ¸ ë ˆë²¨ ê¸°ëŠ¥ë³„ í´ë” êµ¬ì¡°ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜")
    print("=" * 60)
    print()

    # ë°±ì—… ìƒì„±
    timestamp = datetime.now(ZoneInfo('Asia/Seoul')).strftime('%Y%m%d_%H%M%S')
    backup_name = f"data_backup_before_root_migration_{timestamp}"
    backup_dir = base_dir / backup_name

    print(f"ğŸ“¦ ë°±ì—… ìƒì„± ì¤‘: {backup_name}")
    if (base_dir / "data").exists():
        shutil.copytree(base_dir / "data", backup_dir / "data", dirs_exist_ok=True)
    print(f"âœ… ë°±ì—… ì™„ë£Œ: {backup_dir}")
    print()

    migrations = []

    # 1. í¬ë¡¤ëŸ¬ ë°ì´í„° ì´ë™
    print("ğŸ”„ í¬ë¡¤ëŸ¬ í´ë”ë¥¼ ë£¨íŠ¸ë¡œ ì´ë™")
    old_crawler = base_dir / "data" / "crawler"
    new_crawler = base_dir / "crawler"
    if old_crawler.exists():
        if new_crawler.exists():
            # ì´ë¯¸ ì¡´ì¬í•˜ë©´ ë³‘í•©
            for item in old_crawler.iterdir():
                dest = new_crawler / item.name
                if item.is_dir():
                    shutil.copytree(item, dest, dirs_exist_ok=True)
                else:
                    shutil.copy2(item, dest)
            shutil.rmtree(old_crawler)
        else:
            shutil.move(str(old_crawler), str(new_crawler))
        migrations.append(f"  âœ“ data/crawler â†’ crawler/")

        # data ê²½ë¡œë¥¼ rawë¡œ ë³€ê²½ (ë” ëª…í™•í•˜ê²Œ)
        old_data = new_crawler / "raw"
        new_data = new_crawler / "data"
        if old_data.exists() and not new_data.exists():
            shutil.move(str(old_data), str(new_data))
            migrations.append(f"  âœ“ crawler/raw â†’ crawler/data")

    # 2. OCR ë°ì´í„° ì´ë™
    print("ğŸ”„ OCR í´ë”ë¥¼ ë£¨íŠ¸ë¡œ ì´ë™")
    old_ocr = base_dir / "data" / "ocr"
    new_ocr = base_dir / "ocr"
    if old_ocr.exists():
        if new_ocr.exists():
            for item in old_ocr.iterdir():
                dest = new_ocr / item.name
                if item.is_dir():
                    shutil.copytree(item, dest, dirs_exist_ok=True)
                else:
                    shutil.copy2(item, dest)
            shutil.rmtree(old_ocr)
        else:
            shutil.move(str(old_ocr), str(new_ocr))
        migrations.append(f"  âœ“ data/ocr â†’ ocr/")

    # 3. ë³‘í•© ë°ì´í„° ì´ë™
    print("ğŸ”„ ë³‘í•© í´ë”ë¥¼ ë£¨íŠ¸ë¡œ ì´ë™")
    old_merge = base_dir / "data" / "merge"
    new_merge = base_dir / "merge"
    if old_merge.exists():
        if new_merge.exists():
            for item in old_merge.iterdir():
                dest = new_merge / item.name
                if item.is_dir():
                    shutil.copytree(item, dest, dirs_exist_ok=True)
                else:
                    shutil.copy2(item, dest)
            shutil.rmtree(old_merge)
        else:
            shutil.move(str(old_merge), str(new_merge))
        migrations.append(f"  âœ“ data/merge â†’ merge/")

    # 4. Summary ë°ì´í„° ì´ë™
    print("ğŸ”„ Summary í´ë”ë¥¼ ë£¨íŠ¸ë¡œ ì´ë™")
    old_summary = base_dir / "data" / "summary"
    new_summary = base_dir / "summary"
    if old_summary.exists():
        if new_summary.exists():
            for item in old_summary.iterdir():
                dest = new_summary / item.name
                if item.is_dir():
                    shutil.copytree(item, dest, dirs_exist_ok=True)
                else:
                    shutil.copy2(item, dest)
            shutil.rmtree(old_summary)
        else:
            shutil.move(str(old_summary), str(new_summary))
        migrations.append(f"  âœ“ data/summary â†’ summary/")

    # 5. ë¶„ì„ ë°ì´í„° ì´ë™ (ë£¨íŠ¸ë¡œ)
    print("ğŸ”„ ë¶„ì„ í´ë”ë¥¼ ë£¨íŠ¸ë¡œ ì´ë™")
    old_analysis = base_dir / "data" / "analysis"
    new_analysis = base_dir / "analysis"
    if old_analysis.exists():
        if new_analysis.exists():
            for item in old_analysis.iterdir():
                dest = new_analysis / item.name
                if item.is_file():
                    shutil.copy2(item, dest)
            shutil.rmtree(old_analysis)
        else:
            shutil.move(str(old_analysis), str(new_analysis))
        migrations.append(f"  âœ“ data/analysis â†’ analysis/")

    print()
    print("=" * 60)
    print("ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
    print("=" * 60)
    for migration in migrations:
        print(migration)
    print()

    # data í´ë” ì •ë¦¬
    print("ğŸ§¹ ë¹ˆ í´ë” ì •ë¦¬")
    data_dir = base_dir / "data"
    if data_dir.exists():
        # data/outputs, data/temp ë“± ë‚¨ì€ ê²ƒë“¤ í™•ì¸
        remaining = list(data_dir.iterdir())
        if remaining:
            print(f"  âš ï¸  data/ í´ë”ì— ë‚¨ì€ í•­ëª©: {[r.name for r in remaining]}")
        else:
            data_dir.rmdir()
            print(f"  âœ“ data/ í´ë” ì œê±° (ë¹„ì–´ìˆìŒ)")

    print()
    print("âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
    print(f"ğŸ“¦ ë°±ì—… ìœ„ì¹˜: {backup_dir}")
    print()
    print("ìƒˆ í´ë” êµ¬ì¡° (ë£¨íŠ¸ ë ˆë²¨):")
    print("workspace-fee-crawler/")
    print("â”œâ”€â”€ crawler/      # ğŸ” í¬ë¡¤ëŸ¬ ê¸°ëŠ¥")
    print("â”œâ”€â”€ ocr/          # ğŸ“Š OCR ê¸°ëŠ¥")
    print("â”œâ”€â”€ merge/        # ğŸ”€ ë³‘í•© ê¸°ëŠ¥")
    print("â”œâ”€â”€ summary/      # ğŸ“‹ Summary ê¸°ëŠ¥")
    print("â”œâ”€â”€ analysis/     # ğŸ“ˆ ë¶„ì„ ê²°ê³¼")
    print("â”œâ”€â”€ src/          # ì†ŒìŠ¤ ì½”ë“œ")
    print("â””â”€â”€ temp/         # ì„ì‹œ íŒŒì¼")

if __name__ == "__main__":
    migrate_to_root()
