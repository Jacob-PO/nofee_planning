#!/usr/bin/env python3
"""
ê¸°ëŠ¥ë³„ í´ë” êµ¬ì¡°ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜ ìŠ¤í¬ë¦½íŠ¸

ê¸°ì¡´ í†µí•© êµ¬ì¡°:
  data/outputs/merged/, data/outputs/summary/, logs/

ìƒˆë¡œìš´ ê¸°ëŠ¥ë³„ êµ¬ì¡°:
  data/crawler/, data/ocr/, data/merge/, data/summary/
"""

import shutil
from pathlib import Path
from datetime import datetime
from zoneinfo import ZoneInfo

def migrate_data():
    """ê¸°ì¡´ ë°ì´í„°ë¥¼ ìƒˆ êµ¬ì¡°ë¡œ ë§ˆì´ê·¸ë ˆì´ì…˜"""
    base_dir = Path(__file__).parent.parent.parent

    print("=" * 60)
    print("ê¸°ëŠ¥ë³„ í´ë” êµ¬ì¡° ë§ˆì´ê·¸ë ˆì´ì…˜")
    print("=" * 60)
    print()

    # ë°±ì—… ìƒì„±
    timestamp = datetime.now(ZoneInfo('Asia/Seoul')).strftime('%Y%m%d_%H%M%S')
    backup_name = f"data_backup_before_feature_migration_{timestamp}"
    backup_dir = base_dir / backup_name

    print(f"ğŸ“¦ ë°±ì—… ìƒì„± ì¤‘: {backup_name}")
    if (base_dir / "data").exists():
        shutil.copytree(base_dir / "data", backup_dir / "data", dirs_exist_ok=True)
    if (base_dir / "logs").exists():
        shutil.copytree(base_dir / "logs", backup_dir / "logs", dirs_exist_ok=True)
    print(f"âœ… ë°±ì—… ì™„ë£Œ: {backup_dir}")
    print()

    migrations = []

    # 1. í¬ë¡¤ëŸ¬ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
    print("ğŸ”„ í¬ë¡¤ëŸ¬ ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜")
    old_raw = base_dir / "data" / "raw"
    new_raw = base_dir / "data" / "crawler" / "raw"
    if old_raw.exists():
        new_raw.parent.mkdir(parents=True, exist_ok=True)
        if not new_raw.exists():
            shutil.move(str(old_raw), str(new_raw))
            migrations.append(f"  âœ“ data/raw â†’ data/crawler/raw")

    old_checkpoints = base_dir / "data" / "checkpoints"
    new_checkpoints = base_dir / "data" / "crawler" / "checkpoints"
    if old_checkpoints.exists():
        new_checkpoints.parent.mkdir(parents=True, exist_ok=True)
        if not new_checkpoints.exists():
            shutil.move(str(old_checkpoints), str(new_checkpoints))
            migrations.append(f"  âœ“ data/checkpoints â†’ data/crawler/checkpoints")

    old_crawler_logs = base_dir / "logs" / "crawler"
    new_crawler_logs = base_dir / "data" / "crawler" / "logs"
    if old_crawler_logs.exists():
        new_crawler_logs.parent.mkdir(parents=True, exist_ok=True)
        if not new_crawler_logs.exists():
            shutil.move(str(old_crawler_logs), str(new_crawler_logs))
            migrations.append(f"  âœ“ logs/crawler â†’ data/crawler/logs")

    # 2. OCR ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
    print("ğŸ”„ OCR ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜")
    old_ocr = base_dir / "data" / "ocr"
    new_ocr = base_dir / "data" / "ocr"
    # OCRì€ ì´ë¯¸ data/ocrì— ìˆìœ¼ë¯€ë¡œ logsë§Œ ì´ë™

    old_ocr_logs = base_dir / "logs" / "ocr"
    new_ocr_logs = base_dir / "data" / "ocr" / "logs"
    if old_ocr_logs.exists():
        new_ocr_logs.parent.mkdir(parents=True, exist_ok=True)
        if not new_ocr_logs.exists():
            shutil.move(str(old_ocr_logs), str(new_ocr_logs))
            migrations.append(f"  âœ“ logs/ocr â†’ data/ocr/logs")

    # 3. ë³‘í•© ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
    print("ğŸ”„ ë³‘í•© ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜")
    old_merged = base_dir / "data" / "outputs" / "merged"
    new_merged = base_dir / "data" / "merge" / "output"
    if old_merged.exists():
        new_merged.parent.mkdir(parents=True, exist_ok=True)
        if not new_merged.exists():
            shutil.move(str(old_merged), str(new_merged))
            migrations.append(f"  âœ“ data/outputs/merged â†’ data/merge/output")

    old_merge_logs = base_dir / "logs" / "merge"
    new_merge_logs = base_dir / "data" / "merge" / "logs"
    if old_merge_logs.exists():
        new_merge_logs.parent.mkdir(parents=True, exist_ok=True)
        if not new_merge_logs.exists():
            shutil.move(str(old_merge_logs), str(new_merge_logs))
            migrations.append(f"  âœ“ logs/merge â†’ data/merge/logs")

    # 4. Summary ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜
    print("ğŸ”„ Summary ë°ì´í„° ë§ˆì´ê·¸ë ˆì´ì…˜")
    old_summary = base_dir / "data" / "outputs" / "summary"
    new_summary = base_dir / "data" / "summary" / "output"
    if old_summary.exists():
        new_summary.parent.mkdir(parents=True, exist_ok=True)
        if not new_summary.exists():
            shutil.move(str(old_summary), str(new_summary))
            migrations.append(f"  âœ“ data/outputs/summary â†’ data/summary/output")

    old_general_logs = base_dir / "logs" / "general"
    new_summary_logs = base_dir / "data" / "summary" / "logs"
    if old_general_logs.exists():
        new_summary_logs.parent.mkdir(parents=True, exist_ok=True)
        if not new_summary_logs.exists():
            shutil.move(str(old_general_logs), str(new_summary_logs))
            migrations.append(f"  âœ“ logs/general â†’ data/summary/logs")

    # 5. ë¶„ì„ ë°ì´í„° (ê·¸ëŒ€ë¡œ ìœ ì§€)
    print("ğŸ”„ ë¶„ì„ ë°ì´í„° (ìœ„ì¹˜ ìœ ì§€)")
    old_analysis = base_dir / "data" / "analysis"
    if old_analysis.exists():
        migrations.append(f"  âœ“ data/analysis (ìœ ì§€)")

    print()
    print("=" * 60)
    print("ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ")
    print("=" * 60)
    for migration in migrations:
        print(migration)
    print()

    # ë¹ˆ í´ë” ì •ë¦¬
    print("ğŸ§¹ ë¹ˆ í´ë” ì •ë¦¬")
    old_outputs = base_dir / "data" / "outputs"
    if old_outputs.exists() and not list(old_outputs.iterdir()):
        old_outputs.rmdir()
        print(f"  âœ“ data/outputs í´ë” ì œê±°")

    old_logs = base_dir / "logs"
    if old_logs.exists() and not list(old_logs.iterdir()):
        old_logs.rmdir()
        print(f"  âœ“ logs í´ë” ì œê±°")

    print()
    print("âœ… ë§ˆì´ê·¸ë ˆì´ì…˜ ì™„ë£Œ!")
    print(f"ğŸ“¦ ë°±ì—… ìœ„ì¹˜: {backup_dir}")
    print()
    print("ìƒˆ í´ë” êµ¬ì¡°:")
    print("data/")
    print("â”œâ”€â”€ crawler/      # í¬ë¡¤ëŸ¬ ê¸°ëŠ¥")
    print("â”œâ”€â”€ ocr/          # OCR ê¸°ëŠ¥")
    print("â”œâ”€â”€ merge/        # ë³‘í•© ê¸°ëŠ¥")
    print("â”œâ”€â”€ summary/      # Summary ê¸°ëŠ¥")
    print("â””â”€â”€ analysis/     # ë¶„ì„ ê²°ê³¼")

if __name__ == "__main__":
    migrate_data()
