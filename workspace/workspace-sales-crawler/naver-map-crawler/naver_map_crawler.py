import time
from datetime import datetime
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException, NoSuchElementException, ElementClickInterceptedException
from selenium.webdriver.common.keys import Keys
import re

# ê¸°ì¡´ ì£¼ì†Œ ëª©ë¡ ë¡œë“œ
import os
from pathlib import Path

project_root = Path(__file__).parent
addresses_dir = project_root / 'addresses'
results_dir = project_root / 'results'
existing_addresses_file = addresses_dir / 'existing_addresses.txt'

# results ë””ë ‰í† ë¦¬ ìƒì„±
results_dir.mkdir(exist_ok=True)

print("ê¸°ì¡´ ì£¼ì†Œ ëª©ë¡ ë¡œë“œ ì¤‘...")
existing_addresses = set()
try:
    with open(existing_addresses_file, 'r', encoding='utf-8') as f:
        existing_addresses = set(line.strip() for line in f if line.strip())
    print(f"ê¸°ì¡´ ì£¼ì†Œ {len(existing_addresses)}ê°œ ë¡œë“œë¨")
except FileNotFoundError:
    print("existing_addresses.txt íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤. ëª¨ë“  ë°ì´í„°ë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤.")

def setup_driver():
    """í¬ë¡¬ ë“œë¼ì´ë²„ ì„¤ì •"""
    options = webdriver.ChromeOptions()
    # ê¸°ë³¸ ì„¤ì •
    options.add_argument("--disable-blink-features=AutomationControlled")
    options.add_experimental_option("excludeSwitches", ["enable-automation"])
    options.add_experimental_option("useAutomationExtension", False)
    
    # ì¶”ê°€ ì•ˆí‹°íƒì§€ ì„¤ì •
    options.add_argument("--disable-dev-shm-usage")
    options.add_argument("--no-sandbox")
    options.add_argument("--disable-gpu")
    options.add_argument("user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/119.0.0.0 Safari/537.36")
    
    driver = webdriver.Chrome(options=options)
    driver.execute_script("Object.defineProperty(navigator, 'webdriver', {get: () => undefined})")
    driver.implicitly_wait(10)
    
    return driver

def search_naver_map(driver, search_query):
    """ë„¤ì´ë²„ ì§€ë„ì—ì„œ ê²€ìƒ‰"""
    print(f"\nğŸ” '{search_query}' ê²€ìƒ‰ ì¤‘...")
    
    # ë„¤ì´ë²„ ì§€ë„ ì—´ê¸°
    driver.get("https://map.naver.com/")
    time.sleep(3)
    
    # ê²€ìƒ‰ì°½ ì°¾ê¸° ë° ê²€ìƒ‰
    try:
        search_box = WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "input.input_search"))
        )
        search_box.clear()
        search_box.send_keys(search_query)
        search_box.send_keys(Keys.RETURN)
        time.sleep(3)
    except Exception as e:
        print(f"ê²€ìƒ‰ ì¤‘ ì˜¤ë¥˜: {e}")
        return []
    
    # iframeìœ¼ë¡œ ì „í™˜
    try:
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "iframe#searchIframe"))
        )
        driver.switch_to.frame("searchIframe")
    except:
        print("ê²€ìƒ‰ ê²°ê³¼ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return []
    
    return scroll_and_collect_all_places(driver)

def scroll_and_collect_all_places(driver):
    """ëª¨ë“  ê²°ê³¼ë¥¼ ìŠ¤í¬ë¡¤í•˜ë©´ì„œ ìˆ˜ì§‘"""
    all_places = []
    page_num = 1
    duplicates_count = 0
    new_count = 0
    
    while True:
        print(f"\nğŸ“„ í˜ì´ì§€ {page_num} ì²˜ë¦¬ ì¤‘...")
        
        # í˜„ì¬ í˜ì´ì§€ì˜ ëª¨ë“  ê²°ê³¼ ë¡œë“œë¥¼ ìœ„í•´ ìŠ¤í¬ë¡¤
        last_count = 0
        scroll_attempts = 0
        max_scroll_attempts = 10
        
        while scroll_attempts < max_scroll_attempts:
            # í˜„ì¬ ë¡œë“œëœ í•­ëª© ìˆ˜ í™•ì¸
            items = driver.find_elements(By.CSS_SELECTOR, "li._1EKsQ._12tNp")
            current_count = len(items)
            
            if current_count == last_count:
                scroll_attempts += 1
                if scroll_attempts >= 3:  # 3ë²ˆ ì—°ì† ê°™ì€ ìˆ˜ë©´ ìŠ¤í¬ë¡¤ ì¢…ë£Œ
                    break
            else:
                scroll_attempts = 0
            
            last_count = current_count
            
            # ìŠ¤í¬ë¡¤ ë‹¤ìš´
            try:
                scroll_container = driver.find_element(By.CSS_SELECTOR, "div#_pcmap_list_scroll_container")
                driver.execute_script("arguments[0].scrollTop = arguments[0].scrollHeight", scroll_container)
                time.sleep(1)
            except:
                break
        
        print(f"í˜„ì¬ í˜ì´ì§€ì— {current_count}ê°œ í•­ëª© ë°œê²¬")
        
        # ê° ë§¤ì¥ ì •ë³´ ìˆ˜ì§‘
        places = driver.find_elements(By.CSS_SELECTOR, "li._1EKsQ._12tNp")
        
        for idx, place in enumerate(places):
            try:
                # ë§¤ì¥ëª…
                name_elem = place.find_element(By.CSS_SELECTOR, "span._3Apyb")
                name = name_elem.text.strip()
                
                # í´ë¦­í•˜ì—¬ ìƒì„¸ ì •ë³´ ë³´ê¸°
                try:
                    driver.execute_script("arguments[0].scrollIntoView(true);", place)
                    time.sleep(0.5)
                    place.click()
                    time.sleep(1.5)
                except ElementClickInterceptedException:
                    continue
                
                # ë©”ì¸ í”„ë ˆì„ìœ¼ë¡œ ì „í™˜
                driver.switch_to.default_content()
                time.sleep(0.5)
                
                # ìƒì„¸ ì •ë³´ í”„ë ˆì„ìœ¼ë¡œ ì „í™˜
                try:
                    driver.switch_to.frame("entryIframe")
                    time.sleep(1)
                    
                    # ìƒì„¸ ì •ë³´ ìˆ˜ì§‘
                    info = extract_place_details(driver, name)
                    
                    # ì£¼ì†Œ ì¤‘ë³µ ì²´í¬
                    if info['ì£¼ì†Œ'] in existing_addresses:
                        print(f"  {idx + 1}. {name} - ê¸°ì¡´ ë°ì´í„°ì™€ ì¤‘ë³µ (ìŠ¤í‚µ)")
                        duplicates_count += 1
                    # í•„í„°ë§: íœ´ëŒ€í°ì•¡ì„¸ì„œë¦¬ ì—…ì¢… ì œì™¸ & ì „í™”ë²ˆí˜¸ ë˜ëŠ” ì›¹ì‚¬ì´íŠ¸ê°€ ìˆëŠ” ê²½ìš°ë§Œ
                    elif info['ì—…ì¢…'] and 'ì•¡ì„¸ì„œë¦¬' in info['ì—…ì¢…']:
                        print(f"  {idx + 1}. {name} - íœ´ëŒ€í°ì•¡ì„¸ì„œë¦¬ ì—…ì¢… (ìŠ¤í‚µ)")
                    elif info['ì „í™”ë²ˆí˜¸'] or info['ì›¹ì‚¬ì´íŠ¸']:
                        all_places.append(info)
                        new_count += 1
                        print(f"  {idx + 1}. {name} - âœ… ìˆ˜ì§‘ ì™„ë£Œ (ì‹ ê·œ)")
                    else:
                        print(f"  {idx + 1}. {name} - ì—°ë½ì²˜ ì •ë³´ ì—†ìŒ (ìŠ¤í‚µ)")
                    
                except Exception as e:
                    print(f"  {idx + 1}. {name} - ìƒì„¸ ì •ë³´ ìˆ˜ì§‘ ì‹¤íŒ¨: {e}")
                finally:
                    # ë‹¤ì‹œ ê²€ìƒ‰ ê²°ê³¼ í”„ë ˆì„ìœ¼ë¡œ ì „í™˜
                    driver.switch_to.default_content()
                    time.sleep(0.5)
                    driver.switch_to.frame("searchIframe")
                
            except Exception as e:
                print(f"  í•­ëª© ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜: {e}")
                continue
        
        print(f"\ní˜„ì¬ê¹Œì§€: ì‹ ê·œ {new_count}ê°œ, ì¤‘ë³µ {duplicates_count}ê°œ")
        
        # ë‹¤ìŒ í˜ì´ì§€ í™•ì¸
        try:
            # í˜ì´ì§€ë„¤ì´ì…˜ ì°¾ê¸°
            pagination = driver.find_element(By.CSS_SELECTOR, "div._1Z4DX")
            next_button = pagination.find_element(By.CSS_SELECTOR, "a._3pA6R.btn_next")
            
            # ë‹¤ìŒ ë²„íŠ¼ì´ ë¹„í™œì„±í™”ë˜ì—ˆëŠ”ì§€ í™•ì¸
            if "disabled" in next_button.get_attribute("class"):
                print("ë§ˆì§€ë§‰ í˜ì´ì§€ì…ë‹ˆë‹¤.")
                break
            
            # ë‹¤ìŒ í˜ì´ì§€ë¡œ ì´ë™
            next_button.click()
            time.sleep(2)
            page_num += 1
            
        except NoSuchElementException:
            print("ë” ì´ìƒ í˜ì´ì§€ê°€ ì—†ìŠµë‹ˆë‹¤.")
            break
    
    return all_places

def extract_place_details(driver, name):
    """ë§¤ì¥ ìƒì„¸ ì •ë³´ ì¶”ì¶œ"""
    info = {
        'í¬ë¡¤ë§ë‚ ì§œ': datetime.now().strftime('%Y-%m-%d'),
        'ë§¤ì¥ëª…': name,
        'ì£¼ì†Œ': '',
        'ì „í™”ë²ˆí˜¸': '',
        'ì—…ì¢…': '',
        'ì˜ì—…ì‹œê°„': '',
        'ë°©ë¬¸ìë¦¬ë·°': '',
        'ë¸”ë¡œê·¸ë¦¬ë·°': '',
        'ì›¹ì‚¬ì´íŠ¸': ''
    }
    
    try:
        # ì£¼ì†Œ
        try:
            addr_elem = driver.find_element(By.CSS_SELECTOR, "span._2yqUQ")
            info['ì£¼ì†Œ'] = addr_elem.text.strip()
        except:
            pass
        
        # ì „í™”ë²ˆí˜¸
        try:
            phone_elem = driver.find_element(By.CSS_SELECTOR, "span._3ZA0S")
            info['ì „í™”ë²ˆí˜¸'] = phone_elem.text.strip()
        except:
            pass
        
        # ì—…ì¢…
        try:
            category_elem = driver.find_element(By.CSS_SELECTOR, "span._1M85P")
            info['ì—…ì¢…'] = category_elem.text.strip()
        except:
            pass
        
        # ì˜ì—…ì‹œê°„
        try:
            hours_elem = driver.find_element(By.CSS_SELECTOR, "time._1Uj7-")
            info['ì˜ì—…ì‹œê°„'] = hours_elem.text.strip()
        except:
            pass
        
        # ë¦¬ë·° ìˆ˜
        try:
            review_container = driver.find_element(By.CSS_SELECTOR, "div._1kUrA")
            spans = review_container.find_elements(By.CSS_SELECTOR, "span")
            for span in spans:
                text = span.text.strip()
                if "ë°©ë¬¸ìë¦¬ë·°" in text:
                    match = re.search(r'(\d+)', text)
                    if match:
                        info['ë°©ë¬¸ìë¦¬ë·°'] = match.group(1)
                elif "ë¸”ë¡œê·¸ë¦¬ë·°" in text:
                    match = re.search(r'(\d+)', text)
                    if match:
                        info['ë¸”ë¡œê·¸ë¦¬ë·°'] = match.group(1)
        except:
            pass
        
        # ì›¹ì‚¬ì´íŠ¸
        try:
            link_elem = driver.find_element(By.CSS_SELECTOR, "a._11PUw")
            info['ì›¹ì‚¬ì´íŠ¸'] = link_elem.get_attribute('href')
        except:
            pass
    
    except Exception as e:
        print(f"    ìƒì„¸ ì •ë³´ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜: {e}")
    
    return info

def save_results(places):
    """ê²°ê³¼ë¥¼ CSV íŒŒì¼ë¡œ ì €ì¥"""
    if not places:
        print("ì €ì¥í•  ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return

    df = pd.DataFrame(places)

    # ì¶œë ¥ íŒŒì¼ ê²½ë¡œ
    csv_file = results_dir / 'naver_map_results.csv'
    tsv_file = results_dir / 'google_sheets_upload.tsv'

    # ê¸°ì¡´ íŒŒì¼ì´ ìˆìœ¼ë©´ ì¶”ê°€, ì—†ìœ¼ë©´ ìƒˆë¡œ ìƒì„±
    try:
        existing_df = pd.read_csv(csv_file)
        df = pd.concat([existing_df, df], ignore_index=True)
        print(f"ê¸°ì¡´ íŒŒì¼ì— ì¶”ê°€: {len(places)}ê°œ")
    except FileNotFoundError:
        print(f"ìƒˆ íŒŒì¼ ìƒì„±: {len(places)}ê°œ")

    # CSV ì €ì¥
    df.to_csv(csv_file, index=False, encoding='utf-8-sig')
    print(f"ì´ {len(df)}ê°œì˜ ë°ì´í„°ê°€ {csv_file}ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")

    # TSVë¡œë„ ì €ì¥ (Google Sheets ì—…ë¡œë“œìš©)
    df.to_csv(tsv_file, sep='\t', index=False, encoding='utf-8-sig')
    print(f"Google Sheets ì—…ë¡œë“œìš© TSV íŒŒì¼ë„ ìƒì„±ë˜ì—ˆìŠµë‹ˆë‹¤: {tsv_file}")

def main():
    print("=" * 60)
    print("ë„¤ì´ë²„ ì§€ë„ í¬ë¡¤ëŸ¬ (ì¤‘ë³µ ì œì™¸ ë²„ì „)")
    print("=" * 60)
    
    # ì§€ì—­ë³„ ê²€ìƒ‰ì–´ ìƒì„± - ë¶€ì‚° íƒ€ê²Ÿ
    regions = [
        "ë¶€ì‚° í•´ìš´ëŒ€",
        "ë¶€ì‚° ë¶€ì‚°ì§„êµ¬",
        "ë¶€ì‚° ë™ë˜êµ¬",
        "ë¶€ì‚° ë‚¨êµ¬",
        "ë¶€ì‚° ì„œë©´"
    ]

    search_terms = ["íœ´ëŒ€í° ëŒ€ë¦¬ì ", "íœ´ëŒ€í° íŒë§¤ì "]

    # ì§€ì—­ + ê²€ìƒ‰ì–´ ì¡°í•©
    search_queries = []
    for region in regions:
        for term in search_terms:
            search_queries.append(f"{region} {term}")
    
    all_results = []
    
    # ë“œë¼ì´ë²„ ì‹œì‘
    driver = setup_driver()
    
    try:
        for query in search_queries:
            results = search_naver_map(driver, query)
            all_results.extend(results)
            print(f"\n'{query}' ê²€ìƒ‰ ì™„ë£Œ: {len(results)}ê°œ ì‹ ê·œ ë°ì´í„°")
            
            # ì¤‘ê°„ ì €ì¥
            if results:
                save_results(results)
            
            # ë‹¤ìŒ ê²€ìƒ‰ ì „ ëŒ€ê¸°
            time.sleep(3)
    
    except Exception as e:
        print(f"\ní¬ë¡¤ë§ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    
    finally:
        driver.quit()
        print(f"\nğŸ¯ í¬ë¡¤ë§ ì™„ë£Œ! ì´ {len(all_results)}ê°œì˜ ì‹ ê·œ ë°ì´í„° ìˆ˜ì§‘")

if __name__ == "__main__":
    main()