# Naver Map Crawler for Sales Leads

ë„¤ì´ë²„ ì§€ë„ì—ì„œ íœ´ëŒ€í° ë§¤ì¥ ì •ë³´ë¥¼ ìë™ ìˆ˜ì§‘í•˜ëŠ” í¬ë¡¤ë§ ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

## ğŸ“ Project Structure

```
workspace-sales-crawler/
â”œâ”€â”€ naver_map_crawler.py           # Main crawler script
â”œâ”€â”€ google_sheets_uploader.py      # Upload results to Google Sheets
â”œâ”€â”€ download_and_backup.py         # Download and backup data
â”œâ”€â”€ load_existing_addresses.py     # Load existing addresses
â”œâ”€â”€ addresses/                     # Address data files
â”‚   â””â”€â”€ existing_addresses.txt     # Existing addresses (for deduplication)
â”œâ”€â”€ api_keys/                      # API keys
â”‚   â””â”€â”€ google_api_key.json        # Google API credentials
â”œâ”€â”€ results/                       # Output files
â”‚   â”œâ”€â”€ naver_map_results.csv      # Crawling results (CSV)
â”‚   â””â”€â”€ google_sheets_upload.tsv   # Google Sheets upload format
â”œâ”€â”€ google-store-crawler/          # Google search-based crawler
â”œâ”€â”€ naver-store-crawler/           # Naver blog/cafe crawler
â”œâ”€â”€ archive/                       # Archived old versions
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸš€ Features

### Main Features
- **Auto Scrolling**: Automatically scrolls to load all store listings on each page
- **Auto Pagination**: Navigates through all pages until the last page
- **Smart Filtering**: Only collects stores with phone number or website
- **Deduplication**: Prevents duplicate entries based on existing addresses
- **Category Filter**: Excludes phone accessory shops
- **Regional Search**: Searches across all major cities and regions in Korea

### Data Collection
- Crawl Date (í¬ë¡¤ë§ë‚ ì§œ)
- Store Name (ë§¤ì¥ëª…)
- Address (ì£¼ì†Œ)
- Phone Number (ì „í™”ë²ˆí˜¸)
- Business Type (ì—…ì¢…)
- Operating Hours (ì˜ì—…ì‹œê°„)
- Visitor Reviews (ë°©ë¬¸ìë¦¬ë·°)
- Blog Reviews (ë¸”ë¡œê·¸ë¦¬ë·°)
- Website (ì›¹ì‚¬ì´íŠ¸)

## ğŸ“‹ Requirements

- Python 3.8+
- Chrome Browser
- Google API credentials (for Sheets upload)

## ğŸ”§ Installation

```bash
# Create virtual environment
python -m venv venv

# Activate virtual environment
source venv/bin/activate  # Mac/Linux
venv\Scripts\activate     # Windows

# Install dependencies
pip install -r requirements.txt
```

## ğŸ’» Usage

### 1. Run Naver Map Crawler

```bash
python naver_map_crawler.py
```

The script will:
- Load existing addresses from `addresses/existing_addresses.txt`
- Search for stores across multiple regions and keywords
- Save results to `results/naver_map_results.csv`
- Create TSV file for Google Sheets upload

**Configuration**: Edit the script to modify:
- Search regions (line 296-302)
- Search keywords (line 304)
- Number of regions/keywords to search (line 308-310)

### 2. Upload to Google Sheets

```bash
python google_sheets_uploader.py
```

**Prerequisites**:
- Place `google_api_key.json` in `api_keys/` folder
- Enable Google Sheets API in Google Cloud Console
- Grant edit permission to service account email

### 3. Backup Data

```bash
python download_and_backup.py
```

Downloads current data from Google Sheets and creates a backup.

## ğŸ“Š How It Works

### Crawling Process

1. **Load Existing Data**: Reads `addresses/existing_addresses.txt` to avoid duplicates
2. **Generate Search Queries**: Combines regions + keywords
3. **Navigate to Naver Map**: Opens Naver Map and searches for each query
4. **Auto Scroll**: Scrolls through all listings on each page
5. **Collect Details**: Clicks each store to extract detailed information
6. **Filter & Deduplicate**: Applies filters and checks for duplicates
7. **Save Results**: Saves to CSV and TSV files

### Filtering Logic

âœ… **Includes**:
- Stores with phone number OR website
- All business types EXCEPT accessories

âŒ **Excludes**:
- Duplicate addresses (already in database)
- Phone accessory shops (ì•¡ì„¸ì„œë¦¬)
- Stores without contact information

## ğŸ”‘ Google Sheets Setup

### 1. Create Service Account

1. Go to [Google Cloud Console](https://console.cloud.google.com)
2. Create a new project or select existing one
3. Enable Google Sheets API
4. Create Service Account credentials
5. Download JSON key file

### 2. Configure Access

1. Rename downloaded file to `google_api_key.json`
2. Move to `api_keys/` folder
3. Copy service account email (e.g., `xxx@xxx.iam.gserviceaccount.com`)
4. Open your Google Sheet
5. Click "Share" and add service account email with Editor permission

### 3. Update Spreadsheet ID

Edit `google_sheets_uploader.py` line 35:
```python
spreadsheet_id = 'YOUR_SPREADSHEET_ID_HERE'
```

## ğŸ“ Configuration

### Search Regions

Edit regions in `naver_map_crawler.py` (line 296-302):

```python
regions = [
    "ì„œìš¸", "ë¶€ì‚°", "ëŒ€êµ¬", "ì¸ì²œ", "ê´‘ì£¼", "ëŒ€ì „", "ìš¸ì‚°", "ì„¸ì¢…",
    "ê²½ê¸°", "ê°•ì›", "ì¶©ë¶", "ì¶©ë‚¨", "ì „ë¶", "ì „ë‚¨", "ê²½ë¶", "ê²½ë‚¨", "ì œì£¼",
    # Add more regions...
]
```

### Search Keywords

Edit keywords in `naver_map_crawler.py` (line 304):

```python
search_terms = ["íœ´ëŒ€í° ëŒ€ë¦¬ì ", "íœ´ëŒ€í° íŒë§¤ì ", "íœ´ëŒ€í° ì„±ì§€", "ìŠ¤ë§ˆíŠ¸í° ë§¤ì¥"]
```

### Limit Searches

Adjust the slicing in `naver_map_crawler.py` (line 308-310):

```python
for region in regions[:20]:        # First 20 regions
    for term in search_terms[:2]:  # First 2 keywords
```

## âš ï¸ Important Notes

- **Don't touch browser** while crawling is in progress
- **Rate limiting**: Script includes delays to prevent blocking
- **API credentials**: Required for Google Sheets upload
- **Existing addresses**: File is auto-generated on first run
- **Results folder**: Created automatically if it doesn't exist

## ğŸ› Troubleshooting

### Selenium WebDriver Error

```bash
pip install --upgrade selenium
```

### Google Sheets Authentication Failed

- Check `api_keys/google_api_key.json` exists
- Verify Google Sheets API is enabled
- Confirm service account has edit permission on the sheet

### Duplicate Data Collection

- Check `addresses/existing_addresses.txt` is up-to-date
- Run `load_existing_addresses.py` to refresh the address list

### Chrome Driver Issues

The script uses Chrome in automated mode. Make sure:
- Chrome browser is installed
- ChromeDriver is compatible with your Chrome version

## ğŸ“‚ Output Files

- **CSV Results**: `results/naver_map_results.csv`
- **TSV for Sheets**: `results/google_sheets_upload.tsv`
- **Address List**: `addresses/existing_addresses.txt`

## ğŸ”„ Data Flow

```
Naver Map Search
      â†“
  Crawling
      â†“
results/naver_map_results.csv
      â†“
google_sheets_uploader.py
      â†“
Google Sheets (ì˜ì—…DB)
      â†“
download_and_backup.py
      â†“
addresses/existing_addresses.txt
```

## ğŸ“Œ Additional Crawlers

- **google-store-crawler/**: Google search-based crawler
- **naver-store-crawler/**: Naver blog/cafe crawler

See their respective folders for documentation.
